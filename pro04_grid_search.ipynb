{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Piero\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_digits(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'alpha': 0.0001,\n",
       " 'batch_size': 'auto',\n",
       " 'beta_1': 0.9,\n",
       " 'beta_2': 0.999,\n",
       " 'early_stopping': False,\n",
       " 'epsilon': 1e-08,\n",
       " 'hidden_layer_sizes': (100,),\n",
       " 'learning_rate': 'constant',\n",
       " 'learning_rate_init': 0.001,\n",
       " 'max_iter': 200,\n",
       " 'momentum': 0.9,\n",
       " 'n_iter_no_change': 10,\n",
       " 'nesterovs_momentum': True,\n",
       " 'power_t': 0.5,\n",
       " 'random_state': None,\n",
       " 'shuffle': True,\n",
       " 'solver': 'adam',\n",
       " 'tol': 0.0001,\n",
       " 'validation_fraction': 0.1,\n",
       " 'verbose': False,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params_space = {\n",
    "    'alpha': [0.05, 0.1],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1],\n",
    "    'hidden_layer_sizes': [(20,), (10,10), (10,5,5), (20, 20)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(\n",
    "    model,\n",
    "    param_grid=hyper_params_space,\n",
    "    verbose=2,\n",
    "    cv=2,\n",
    "    refit='precision_macro',\n",
    "    scoring=['accuracy', 'precision_macro', 'recall_macro']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 24 candidates, totalling 48 fits\n",
      "[CV] alpha=0.05, hidden_layer_sizes=(20,), learning_rate_init=0.001 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\Piero\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.05, hidden_layer_sizes=(20,), learning_rate_init=0.001, total=   0.7s\n",
      "[CV] alpha=0.05, hidden_layer_sizes=(20,), learning_rate_init=0.001 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Piero\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.05, hidden_layer_sizes=(20,), learning_rate_init=0.001, total=   0.7s\n",
      "[CV] alpha=0.05, hidden_layer_sizes=(20,), learning_rate_init=0.01 ...\n",
      "[CV]  alpha=0.05, hidden_layer_sizes=(20,), learning_rate_init=0.01, total=   0.7s\n",
      "[CV] alpha=0.05, hidden_layer_sizes=(20,), learning_rate_init=0.01 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Piero\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.05, hidden_layer_sizes=(20,), learning_rate_init=0.01, total=   1.3s\n",
      "[CV] alpha=0.05, hidden_layer_sizes=(20,), learning_rate_init=0.1 ....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Piero\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Piero\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.05, hidden_layer_sizes=(20,), learning_rate_init=0.1, total=   0.6s\n",
      "[CV] alpha=0.05, hidden_layer_sizes=(20,), learning_rate_init=0.1 ....\n",
      "[CV]  alpha=0.05, hidden_layer_sizes=(20,), learning_rate_init=0.1, total=   0.1s\n",
      "[CV] alpha=0.05, hidden_layer_sizes=(10, 10), learning_rate_init=0.001 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Piero\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.05, hidden_layer_sizes=(10, 10), learning_rate_init=0.001, total=   1.4s\n",
      "[CV] alpha=0.05, hidden_layer_sizes=(10, 10), learning_rate_init=0.001 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Piero\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.05, hidden_layer_sizes=(10, 10), learning_rate_init=0.001, total=   1.7s\n",
      "[CV] alpha=0.05, hidden_layer_sizes=(10, 10), learning_rate_init=0.01 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Piero\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.05, hidden_layer_sizes=(10, 10), learning_rate_init=0.01, total=   1.1s\n",
      "[CV] alpha=0.05, hidden_layer_sizes=(10, 10), learning_rate_init=0.01 \n",
      "[CV]  alpha=0.05, hidden_layer_sizes=(10, 10), learning_rate_init=0.01, total=   0.8s\n",
      "[CV] alpha=0.05, hidden_layer_sizes=(10, 10), learning_rate_init=0.1 .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Piero\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.05, hidden_layer_sizes=(10, 10), learning_rate_init=0.1, total=   0.5s\n",
      "[CV] alpha=0.05, hidden_layer_sizes=(10, 10), learning_rate_init=0.1 .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Piero\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.05, hidden_layer_sizes=(10, 10), learning_rate_init=0.1, total=   0.4s\n",
      "[CV] alpha=0.05, hidden_layer_sizes=(10, 5, 5), learning_rate_init=0.001 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Piero\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.05, hidden_layer_sizes=(10, 5, 5), learning_rate_init=0.001, total=   1.4s\n",
      "[CV] alpha=0.05, hidden_layer_sizes=(10, 5, 5), learning_rate_init=0.001 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Piero\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.05, hidden_layer_sizes=(10, 5, 5), learning_rate_init=0.001, total=   1.3s\n",
      "[CV] alpha=0.05, hidden_layer_sizes=(10, 5, 5), learning_rate_init=0.01 \n",
      "[CV]  alpha=0.05, hidden_layer_sizes=(10, 5, 5), learning_rate_init=0.01, total=   1.1s\n",
      "[CV] alpha=0.05, hidden_layer_sizes=(10, 5, 5), learning_rate_init=0.01 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Piero\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Piero\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.05, hidden_layer_sizes=(10, 5, 5), learning_rate_init=0.01, total=   1.1s\n",
      "[CV] alpha=0.05, hidden_layer_sizes=(10, 5, 5), learning_rate_init=0.1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Piero\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.05, hidden_layer_sizes=(10, 5, 5), learning_rate_init=0.1, total=   0.5s\n",
      "[CV] alpha=0.05, hidden_layer_sizes=(10, 5, 5), learning_rate_init=0.1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Piero\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.05, hidden_layer_sizes=(10, 5, 5), learning_rate_init=0.1, total=   0.5s\n",
      "[CV] alpha=0.05, hidden_layer_sizes=(20, 20), learning_rate_init=0.001 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Piero\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.05, hidden_layer_sizes=(20, 20), learning_rate_init=0.001, total=   1.1s\n",
      "[CV] alpha=0.05, hidden_layer_sizes=(20, 20), learning_rate_init=0.001 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Piero\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.05, hidden_layer_sizes=(20, 20), learning_rate_init=0.001, total=   1.2s\n",
      "[CV] alpha=0.05, hidden_layer_sizes=(20, 20), learning_rate_init=0.01 \n",
      "[CV]  alpha=0.05, hidden_layer_sizes=(20, 20), learning_rate_init=0.01, total=   0.5s\n",
      "[CV] alpha=0.05, hidden_layer_sizes=(20, 20), learning_rate_init=0.01 \n",
      "[CV]  alpha=0.05, hidden_layer_sizes=(20, 20), learning_rate_init=0.01, total=   0.5s\n",
      "[CV] alpha=0.05, hidden_layer_sizes=(20, 20), learning_rate_init=0.1 .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Piero\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Piero\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Piero\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.05, hidden_layer_sizes=(20, 20), learning_rate_init=0.1, total=   1.8s\n",
      "[CV] alpha=0.05, hidden_layer_sizes=(20, 20), learning_rate_init=0.1 .\n",
      "[CV]  alpha=0.05, hidden_layer_sizes=(20, 20), learning_rate_init=0.1, total=   0.1s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(20,), learning_rate_init=0.001 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Piero\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.1, hidden_layer_sizes=(20,), learning_rate_init=0.001, total=   1.4s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(20,), learning_rate_init=0.001 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Piero\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.1, hidden_layer_sizes=(20,), learning_rate_init=0.001, total=   1.2s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(20,), learning_rate_init=0.01 ....\n",
      "[CV]  alpha=0.1, hidden_layer_sizes=(20,), learning_rate_init=0.01, total=   0.9s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(20,), learning_rate_init=0.01 ....\n",
      "[CV]  alpha=0.1, hidden_layer_sizes=(20,), learning_rate_init=0.01, total=   0.6s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(20,), learning_rate_init=0.1 .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Piero\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.1, hidden_layer_sizes=(20,), learning_rate_init=0.1, total=   0.5s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(20,), learning_rate_init=0.1 .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Piero\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.1, hidden_layer_sizes=(20,), learning_rate_init=0.1, total=   0.4s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(10, 10), learning_rate_init=0.001 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Piero\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.1, hidden_layer_sizes=(10, 10), learning_rate_init=0.001, total=   1.9s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(10, 10), learning_rate_init=0.001 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Piero\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.1, hidden_layer_sizes=(10, 10), learning_rate_init=0.001, total=   1.2s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(10, 10), learning_rate_init=0.01 .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Piero\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.1, hidden_layer_sizes=(10, 10), learning_rate_init=0.01, total=   1.0s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(10, 10), learning_rate_init=0.01 .\n",
      "[CV]  alpha=0.1, hidden_layer_sizes=(10, 10), learning_rate_init=0.01, total=   0.6s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(10, 10), learning_rate_init=0.1 ..\n",
      "[CV]  alpha=0.1, hidden_layer_sizes=(10, 10), learning_rate_init=0.1, total=   0.1s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(10, 10), learning_rate_init=0.1 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Piero\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Piero\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Piero\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.1, hidden_layer_sizes=(10, 10), learning_rate_init=0.1, total=   1.0s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(10, 5, 5), learning_rate_init=0.001 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Piero\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.1, hidden_layer_sizes=(10, 5, 5), learning_rate_init=0.001, total=   1.2s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(10, 5, 5), learning_rate_init=0.001 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Piero\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.1, hidden_layer_sizes=(10, 5, 5), learning_rate_init=0.001, total=   1.1s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(10, 5, 5), learning_rate_init=0.01 \n",
      "[CV]  alpha=0.1, hidden_layer_sizes=(10, 5, 5), learning_rate_init=0.01, total=   0.8s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(10, 5, 5), learning_rate_init=0.01 \n",
      "[CV]  alpha=0.1, hidden_layer_sizes=(10, 5, 5), learning_rate_init=0.01, total=   1.5s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(10, 5, 5), learning_rate_init=0.1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Piero\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.1, hidden_layer_sizes=(10, 5, 5), learning_rate_init=0.1, total=   0.8s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(10, 5, 5), learning_rate_init=0.1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Piero\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.1, hidden_layer_sizes=(10, 5, 5), learning_rate_init=0.1, total=   0.4s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(20, 20), learning_rate_init=0.001 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Piero\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.1, hidden_layer_sizes=(20, 20), learning_rate_init=0.001, total=   1.3s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(20, 20), learning_rate_init=0.001 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Piero\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.1, hidden_layer_sizes=(20, 20), learning_rate_init=0.001, total=   1.2s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(20, 20), learning_rate_init=0.01 .\n",
      "[CV]  alpha=0.1, hidden_layer_sizes=(20, 20), learning_rate_init=0.01, total=   0.6s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(20, 20), learning_rate_init=0.01 .\n",
      "[CV]  alpha=0.1, hidden_layer_sizes=(20, 20), learning_rate_init=0.01, total=   0.7s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(20, 20), learning_rate_init=0.1 ..\n",
      "[CV]  alpha=0.1, hidden_layer_sizes=(20, 20), learning_rate_init=0.1, total=   0.1s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(20, 20), learning_rate_init=0.1 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Piero\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Piero\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[Parallel(n_jobs=1)]: Done  48 out of  48 | elapsed:   42.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.1, hidden_layer_sizes=(20, 20), learning_rate_init=0.1, total=   0.5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise-deprecating',\n",
       "             estimator=MLPClassifier(activation='relu', alpha=0.05,\n",
       "                                     batch_size='auto', beta_1=0.9,\n",
       "                                     beta_2=0.999, early_stopping=False,\n",
       "                                     epsilon=1e-08, hidden_layer_sizes=(20, 20),\n",
       "                                     learning_rate='constant',\n",
       "                                     learning_rate_init=0.01, max_iter=200,\n",
       "                                     momentum=0.9, n_iter_no_change=10,\n",
       "                                     nesterovs_momentum=True, power_t=0.5,\n",
       "                                     random_state...\n",
       "                                     solver='adam', tol=0.0001,\n",
       "                                     validation_fraction=0.1, verbose=False,\n",
       "                                     warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'alpha': [0.05, 0.1],\n",
       "                         'hidden_layer_sizes': [(20,), (10, 10), (10, 5, 5),\n",
       "                                                (20, 20)],\n",
       "                         'learning_rate_init': [0.001, 0.01, 0.1]},\n",
       "             pre_dispatch='2*n_jobs', refit='precision_macro',\n",
       "             return_train_score=False,\n",
       "             scoring=['accuracy', 'precision_macro', 'recall_macro'],\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.1, 'hidden_layer_sizes': (20,), 'learning_rate_init': 0.01}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.955876915960481"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.1, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(20,), learning_rate='constant',\n",
       "              learning_rate_init=0.01, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9688888888888889"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'alpha': 0.1,\n",
       " 'batch_size': 'auto',\n",
       " 'beta_1': 0.9,\n",
       " 'beta_2': 0.999,\n",
       " 'early_stopping': False,\n",
       " 'epsilon': 1e-08,\n",
       " 'hidden_layer_sizes': (20,),\n",
       " 'learning_rate': 'constant',\n",
       " 'learning_rate_init': 0.01,\n",
       " 'max_iter': 200,\n",
       " 'momentum': 0.9,\n",
       " 'n_iter_no_change': 10,\n",
       " 'nesterovs_momentum': True,\n",
       " 'power_t': 0.5,\n",
       " 'random_state': None,\n",
       " 'shuffle': True,\n",
       " 'solver': 'adam',\n",
       " 'tol': 0.0001,\n",
       " 'validation_fraction': 0.1,\n",
       " 'verbose': False,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MLPClassifier(**model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.05, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(20, 20), learning_rate='constant',\n",
       "              learning_rate_init=0.01, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.05, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(20, 20), learning_rate='constant',\n",
       "              learning_rate_init=0.01, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2 = MLPClassifier()\n",
    "m2.set_params(**model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_net.pkl']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(model, 'best_net.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.69392478, 0.99039352, 0.33410501, 1.56456447, 0.95165789,\n",
       "        0.43633199, 1.36335611, 1.05368531, 0.51261961, 1.14543879,\n",
       "        0.49316823, 0.96229517, 1.29881585, 0.70438647, 0.42785633,\n",
       "        1.55154717, 0.81286991, 0.5218606 , 1.17585123, 1.10703182,\n",
       "        0.56575525, 1.24791384, 0.63878822, 0.26978028]),\n",
       " 'std_fit_time': array([0.04366362, 0.33858836, 0.21542335, 0.13937259, 0.13384569,\n",
       "        0.04538107, 0.03889441, 0.00847423, 0.01095784, 0.01147521,\n",
       "        0.0124687 , 0.86056936, 0.11001003, 0.15485644, 0.07579768,\n",
       "        0.30687177, 0.21438444, 0.45204902, 0.03890097, 0.33510041,\n",
       "        0.17925227, 0.01521063, 0.0593369 , 0.18899286]),\n",
       " 'mean_score_time': array([0.00648999, 0.01347411, 0.0119772 , 0.01046979, 0.0064888 ,\n",
       "        0.00848174, 0.00498462, 0.00599015, 0.00848031, 0.00647819,\n",
       "        0.00849748, 0.014961  , 0.00447178, 0.00847769, 0.00750232,\n",
       "        0.00847483, 0.00598514, 0.00548422, 0.00947952, 0.01047444,\n",
       "        0.00749159, 0.00749707, 0.00797176, 0.01146805]),\n",
       " 'std_score_time': array([1.50442123e-03, 5.09858131e-04, 2.14576721e-06, 2.49230862e-03,\n",
       "        1.50990486e-03, 1.48797035e-03, 1.43051147e-06, 2.00188160e-03,\n",
       "        1.49321556e-03, 4.96029854e-04, 4.80651855e-04, 2.99119949e-03,\n",
       "        5.13315201e-04, 3.49092484e-03, 1.48224831e-03, 3.49283218e-03,\n",
       "        1.99687481e-03, 1.49571896e-03, 4.94241714e-04, 5.48124313e-03,\n",
       "        1.50728226e-03, 1.49226189e-03, 9.89437103e-04, 5.00798225e-04]),\n",
       " 'param_alpha': masked_array(data=[0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,\n",
       "                    0.05, 0.05, 0.05, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_hidden_layer_sizes': masked_array(data=[(20,), (20,), (20,), (10, 10), (10, 10), (10, 10),\n",
       "                    (10, 5, 5), (10, 5, 5), (10, 5, 5), (20, 20), (20, 20),\n",
       "                    (20, 20), (20,), (20,), (20,), (10, 10), (10, 10),\n",
       "                    (10, 10), (10, 5, 5), (10, 5, 5), (10, 5, 5), (20, 20),\n",
       "                    (20, 20), (20, 20)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learning_rate_init': masked_array(data=[0.001, 0.01, 0.1, 0.001, 0.01, 0.1, 0.001, 0.01, 0.1,\n",
       "                    0.001, 0.01, 0.1, 0.001, 0.01, 0.1, 0.001, 0.01, 0.1,\n",
       "                    0.001, 0.01, 0.1, 0.001, 0.01, 0.1],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'alpha': 0.05,\n",
       "   'hidden_layer_sizes': (20,),\n",
       "   'learning_rate_init': 0.001},\n",
       "  {'alpha': 0.05, 'hidden_layer_sizes': (20,), 'learning_rate_init': 0.01},\n",
       "  {'alpha': 0.05, 'hidden_layer_sizes': (20,), 'learning_rate_init': 0.1},\n",
       "  {'alpha': 0.05, 'hidden_layer_sizes': (10, 10), 'learning_rate_init': 0.001},\n",
       "  {'alpha': 0.05, 'hidden_layer_sizes': (10, 10), 'learning_rate_init': 0.01},\n",
       "  {'alpha': 0.05, 'hidden_layer_sizes': (10, 10), 'learning_rate_init': 0.1},\n",
       "  {'alpha': 0.05,\n",
       "   'hidden_layer_sizes': (10, 5, 5),\n",
       "   'learning_rate_init': 0.001},\n",
       "  {'alpha': 0.05,\n",
       "   'hidden_layer_sizes': (10, 5, 5),\n",
       "   'learning_rate_init': 0.01},\n",
       "  {'alpha': 0.05, 'hidden_layer_sizes': (10, 5, 5), 'learning_rate_init': 0.1},\n",
       "  {'alpha': 0.05, 'hidden_layer_sizes': (20, 20), 'learning_rate_init': 0.001},\n",
       "  {'alpha': 0.05, 'hidden_layer_sizes': (20, 20), 'learning_rate_init': 0.01},\n",
       "  {'alpha': 0.05, 'hidden_layer_sizes': (20, 20), 'learning_rate_init': 0.1},\n",
       "  {'alpha': 0.1, 'hidden_layer_sizes': (20,), 'learning_rate_init': 0.001},\n",
       "  {'alpha': 0.1, 'hidden_layer_sizes': (20,), 'learning_rate_init': 0.01},\n",
       "  {'alpha': 0.1, 'hidden_layer_sizes': (20,), 'learning_rate_init': 0.1},\n",
       "  {'alpha': 0.1, 'hidden_layer_sizes': (10, 10), 'learning_rate_init': 0.001},\n",
       "  {'alpha': 0.1, 'hidden_layer_sizes': (10, 10), 'learning_rate_init': 0.01},\n",
       "  {'alpha': 0.1, 'hidden_layer_sizes': (10, 10), 'learning_rate_init': 0.1},\n",
       "  {'alpha': 0.1,\n",
       "   'hidden_layer_sizes': (10, 5, 5),\n",
       "   'learning_rate_init': 0.001},\n",
       "  {'alpha': 0.1, 'hidden_layer_sizes': (10, 5, 5), 'learning_rate_init': 0.01},\n",
       "  {'alpha': 0.1, 'hidden_layer_sizes': (10, 5, 5), 'learning_rate_init': 0.1},\n",
       "  {'alpha': 0.1, 'hidden_layer_sizes': (20, 20), 'learning_rate_init': 0.001},\n",
       "  {'alpha': 0.1, 'hidden_layer_sizes': (20, 20), 'learning_rate_init': 0.01},\n",
       "  {'alpha': 0.1, 'hidden_layer_sizes': (20, 20), 'learning_rate_init': 0.1}],\n",
       " 'split0_test_accuracy': array([0.93916914, 0.93323442, 0.20029674, 0.89762611, 0.89762611,\n",
       "        0.09643917, 0.81602374, 0.82937685, 0.10385757, 0.93026706,\n",
       "        0.94658754, 0.10089021, 0.92284866, 0.94658754, 0.32344214,\n",
       "        0.91097923, 0.90207715, 0.10237389, 0.86350148, 0.8620178 ,\n",
       "        0.10385757, 0.90949555, 0.95103858, 0.10534125]),\n",
       " 'split1_test_accuracy': array([0.94056464, 0.92867756, 0.19316493, 0.9063893 , 0.86775632,\n",
       "        0.20505201, 0.87518574, 0.37890045, 0.10104012, 0.95096582,\n",
       "        0.96136701, 0.10401189, 0.95393759, 0.9628529 , 0.10401189,\n",
       "        0.90936107, 0.91976226, 0.10104012, 0.84398217, 0.77711738,\n",
       "        0.31054978, 0.95839525, 0.93016345, 0.2897474 ]),\n",
       " 'mean_test_accuracy': array([0.93986637, 0.93095768, 0.19673348, 0.90200445, 0.8827023 ,\n",
       "        0.15070527, 0.84558278, 0.60430586, 0.10244989, 0.94060876,\n",
       "        0.95397179, 0.10244989, 0.93838159, 0.95471418, 0.21380846,\n",
       "        0.91017075, 0.91091314, 0.1017075 , 0.85374907, 0.81959911,\n",
       "        0.20712695, 0.93392725, 0.94060876, 0.19747587]),\n",
       " 'std_test_accuracy': array([0.00069775, 0.00227843, 0.0035659 , 0.00438159, 0.01493489,\n",
       "        0.0543064 , 0.02958099, 0.22523814, 0.00140872, 0.01034938,\n",
       "        0.00738974, 0.00156084, 0.01554446, 0.00813268, 0.10971509,\n",
       "        0.00080908, 0.00884255, 0.00066688, 0.00975965, 0.0424502 ,\n",
       "        0.10334608, 0.02444984, 0.01043756, 0.09220305]),\n",
       " 'rank_test_accuracy': array([ 5,  8, 20, 11, 12, 21, 14, 16, 22,  3,  2, 22,  6,  1, 17, 10,  9,\n",
       "        24, 13, 15, 18,  7,  3, 19]),\n",
       " 'split0_test_precision_macro': array([0.9383418 , 0.93548863, 0.12541458, 0.89816264, 0.89835299,\n",
       "        0.00964392, 0.8248089 , 0.8326788 , 0.01038576, 0.93141899,\n",
       "        0.94686513, 0.01008902, 0.92596783, 0.94794116, 0.22806876,\n",
       "        0.91554902, 0.90180618, 0.01023739, 0.86505884, 0.86576899,\n",
       "        0.01038576, 0.90954753, 0.95216999, 0.01053412]),\n",
       " 'split1_test_precision_macro': array([0.94050638, 0.9309431 , 0.12479561, 0.90689824, 0.87205324,\n",
       "        0.14141216, 0.87568144, 0.27678542, 0.01010401, 0.95049791,\n",
       "        0.96154709, 0.01040119, 0.95314882, 0.96382446, 0.01040119,\n",
       "        0.90966557, 0.92113848, 0.01010401, 0.84357214, 0.78191989,\n",
       "        0.216006  , 0.95822733, 0.93005174, 0.235625  ]),\n",
       " 'mean_test_precision_macro': array([0.93942329, 0.93321756, 0.12510532, 0.9025272 , 0.88521287,\n",
       "        0.07547913, 0.85022629, 0.55493845, 0.01024499, 0.94095137,\n",
       "        0.95420066, 0.01024499, 0.93954824, 0.95587692, 0.11931577,\n",
       "        0.91260948, 0.91146515, 0.01017075, 0.85432347, 0.82387556,\n",
       "        0.11311955, 0.93386936, 0.94111907, 0.12299601]),\n",
       " 'std_test_precision_macro': array([1.08228803e-03, 2.27276523e-03, 3.09481517e-04, 4.36780141e-03,\n",
       "        1.31498715e-02, 6.58841025e-02, 2.54362646e-02, 2.77946617e-01,\n",
       "        1.40872356e-04, 9.53945654e-03, 7.34097610e-03, 1.56083925e-04,\n",
       "        1.35904918e-02, 7.94164491e-03, 1.08833756e-01, 2.94172027e-03,\n",
       "        9.66614521e-03, 6.66884001e-05, 1.07433470e-02, 4.19245389e-02,\n",
       "        1.02810092e-01, 2.43398936e-02, 1.10591188e-02, 1.12545409e-01]),\n",
       " 'rank_test_precision_macro': array([ 6,  8, 17, 11, 12, 21, 14, 16, 22,  4,  2, 22,  5,  1, 19,  9, 10,\n",
       "        24, 13, 15, 20,  7,  3, 18]),\n",
       " 'split0_test_recall_macro': array([0.93808273, 0.93194308, 0.19841492, 0.89620032, 0.89676294,\n",
       "        0.1       , 0.81422757, 0.82813194, 0.1       , 0.92886709,\n",
       "        0.94587155, 0.1       , 0.92112717, 0.94581195, 0.31691816,\n",
       "        0.90960115, 0.901367  , 0.1       , 0.86294443, 0.86064194,\n",
       "        0.1       , 0.90847709, 0.95014448, 0.1       ]),\n",
       " 'split1_test_recall_macro': array([0.93985396, 0.92867131, 0.19145221, 0.90593076, 0.86664244,\n",
       "        0.19995976, 0.87171742, 0.37887152, 0.1       , 0.95028764,\n",
       "        0.96092154, 0.1       , 0.95318188, 0.96254891, 0.1       ,\n",
       "        0.90891861, 0.9190099 , 0.1       , 0.8427687 , 0.77523752,\n",
       "        0.30779652, 0.9581685 , 0.92990044, 0.2900509 ]),\n",
       " 'mean_test_recall_macro': array([0.93896768, 0.93030841, 0.19493615, 0.90106193, 0.88171387,\n",
       "        0.14994277, 0.84295115, 0.60366849, 0.1       , 0.93956941,\n",
       "        0.95339096, 0.1       , 0.93714263, 0.95417422, 0.2085396 ,\n",
       "        0.90926013, 0.9101819 , 0.1       , 0.85286406, 0.81797143,\n",
       "        0.20382113, 0.93330435, 0.94002997, 0.1949549 ]),\n",
       " 'std_test_recall_macro': array([8.85613951e-04, 1.63588492e-03, 3.48135531e-03, 4.86522166e-03,\n",
       "        1.50602463e-02, 4.99798655e-02, 2.87449164e-02, 2.24630148e-01,\n",
       "        1.38777878e-17, 1.07102753e-02, 7.52499114e-03, 1.38777878e-17,\n",
       "        1.60273497e-02, 8.36847651e-03, 1.08459049e-01, 3.41272636e-04,\n",
       "        8.82144914e-03, 1.38777878e-17, 1.00878601e-02, 4.27022025e-02,\n",
       "        1.03898231e-01, 2.48456947e-02, 1.01220134e-02, 9.50254222e-02]),\n",
       " 'rank_test_recall_macro': array([ 5,  8, 20, 11, 12, 21, 14, 16, 22,  4,  2, 22,  6,  1, 17, 10,  9,\n",
       "        22, 13, 15, 18,  7,  3, 19])}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
       "       'param_alpha', 'param_hidden_layer_sizes', 'param_learning_rate_init',\n",
       "       'params', 'split0_test_accuracy', 'split1_test_accuracy',\n",
       "       'mean_test_accuracy', 'std_test_accuracy', 'rank_test_accuracy',\n",
       "       'split0_test_precision_macro', 'split1_test_precision_macro',\n",
       "       'mean_test_precision_macro', 'std_test_precision_macro',\n",
       "       'rank_test_precision_macro', 'split0_test_recall_macro',\n",
       "       'split1_test_recall_macro', 'mean_test_recall_macro',\n",
       "       'std_test_recall_macro', 'rank_test_recall_macro'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>param_learning_rate_init</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>split0_test_precision_macro</th>\n",
       "      <th>split1_test_precision_macro</th>\n",
       "      <th>mean_test_precision_macro</th>\n",
       "      <th>std_test_precision_macro</th>\n",
       "      <th>rank_test_precision_macro</th>\n",
       "      <th>split0_test_recall_macro</th>\n",
       "      <th>split1_test_recall_macro</th>\n",
       "      <th>mean_test_recall_macro</th>\n",
       "      <th>std_test_recall_macro</th>\n",
       "      <th>rank_test_recall_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.704386</td>\n",
       "      <td>0.154856</td>\n",
       "      <td>0.008478</td>\n",
       "      <td>0.003491</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(20,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.1, 'hidden_layer_sizes': (20,), 'l...</td>\n",
       "      <td>0.946588</td>\n",
       "      <td>0.962853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947941</td>\n",
       "      <td>0.963824</td>\n",
       "      <td>0.955877</td>\n",
       "      <td>0.007942</td>\n",
       "      <td>1</td>\n",
       "      <td>0.945812</td>\n",
       "      <td>0.962549</td>\n",
       "      <td>0.954174</td>\n",
       "      <td>0.008368</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.493168</td>\n",
       "      <td>0.012469</td>\n",
       "      <td>0.008497</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(20, 20)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.05, 'hidden_layer_sizes': (20, 20)...</td>\n",
       "      <td>0.946588</td>\n",
       "      <td>0.961367</td>\n",
       "      <td>...</td>\n",
       "      <td>0.946865</td>\n",
       "      <td>0.961547</td>\n",
       "      <td>0.954201</td>\n",
       "      <td>0.007341</td>\n",
       "      <td>2</td>\n",
       "      <td>0.945872</td>\n",
       "      <td>0.960922</td>\n",
       "      <td>0.953391</td>\n",
       "      <td>0.007525</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.638788</td>\n",
       "      <td>0.059337</td>\n",
       "      <td>0.007972</td>\n",
       "      <td>0.000989</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(20, 20)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.1, 'hidden_layer_sizes': (20, 20),...</td>\n",
       "      <td>0.951039</td>\n",
       "      <td>0.930163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.952170</td>\n",
       "      <td>0.930052</td>\n",
       "      <td>0.941119</td>\n",
       "      <td>0.011059</td>\n",
       "      <td>3</td>\n",
       "      <td>0.950144</td>\n",
       "      <td>0.929900</td>\n",
       "      <td>0.940030</td>\n",
       "      <td>0.010122</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows  23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "13       0.704386      0.154856         0.008478        0.003491         0.1   \n",
       "10       0.493168      0.012469         0.008497        0.000481        0.05   \n",
       "22       0.638788      0.059337         0.007972        0.000989         0.1   \n",
       "\n",
       "   param_hidden_layer_sizes param_learning_rate_init  \\\n",
       "13                    (20,)                     0.01   \n",
       "10                 (20, 20)                     0.01   \n",
       "22                 (20, 20)                     0.01   \n",
       "\n",
       "                                               params  split0_test_accuracy  \\\n",
       "13  {'alpha': 0.1, 'hidden_layer_sizes': (20,), 'l...              0.946588   \n",
       "10  {'alpha': 0.05, 'hidden_layer_sizes': (20, 20)...              0.946588   \n",
       "22  {'alpha': 0.1, 'hidden_layer_sizes': (20, 20),...              0.951039   \n",
       "\n",
       "    split1_test_accuracy  ...  split0_test_precision_macro  \\\n",
       "13              0.962853  ...                     0.947941   \n",
       "10              0.961367  ...                     0.946865   \n",
       "22              0.930163  ...                     0.952170   \n",
       "\n",
       "    split1_test_precision_macro  mean_test_precision_macro  \\\n",
       "13                     0.963824                   0.955877   \n",
       "10                     0.961547                   0.954201   \n",
       "22                     0.930052                   0.941119   \n",
       "\n",
       "    std_test_precision_macro  rank_test_precision_macro  \\\n",
       "13                  0.007942                          1   \n",
       "10                  0.007341                          2   \n",
       "22                  0.011059                          3   \n",
       "\n",
       "    split0_test_recall_macro  split1_test_recall_macro  \\\n",
       "13                  0.945812                  0.962549   \n",
       "10                  0.945872                  0.960922   \n",
       "22                  0.950144                  0.929900   \n",
       "\n",
       "    mean_test_recall_macro  std_test_recall_macro  rank_test_recall_macro  \n",
       "13                0.954174               0.008368                       1  \n",
       "10                0.953391               0.007525                       2  \n",
       "22                0.940030               0.010122                       3  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='mean_test_precision_macro', ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "      <th>split0_test_precision_macro</th>\n",
       "      <th>split1_test_precision_macro</th>\n",
       "      <th>mean_test_precision_macro</th>\n",
       "      <th>std_test_precision_macro</th>\n",
       "      <th>rank_test_precision_macro</th>\n",
       "      <th>split0_test_recall_macro</th>\n",
       "      <th>split1_test_recall_macro</th>\n",
       "      <th>mean_test_recall_macro</th>\n",
       "      <th>std_test_recall_macro</th>\n",
       "      <th>rank_test_recall_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>24.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.867667</td>\n",
       "      <td>0.166245</td>\n",
       "      <td>0.008398</td>\n",
       "      <td>0.001580</td>\n",
       "      <td>0.649790</td>\n",
       "      <td>0.644750</td>\n",
       "      <td>0.647272</td>\n",
       "      <td>0.032585</td>\n",
       "      <td>12.416667</td>\n",
       "      <td>0.621029</td>\n",
       "      <td>0.613971</td>\n",
       "      <td>0.617503</td>\n",
       "      <td>0.035587</td>\n",
       "      <td>12.458333</td>\n",
       "      <td>0.648147</td>\n",
       "      <td>0.643412</td>\n",
       "      <td>0.645781</td>\n",
       "      <td>3.234240e-02</td>\n",
       "      <td>12.37500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.386487</td>\n",
       "      <td>0.192619</td>\n",
       "      <td>0.002651</td>\n",
       "      <td>0.001287</td>\n",
       "      <td>0.370969</td>\n",
       "      <td>0.360832</td>\n",
       "      <td>0.360611</td>\n",
       "      <td>0.052631</td>\n",
       "      <td>7.064404</td>\n",
       "      <td>0.414861</td>\n",
       "      <td>0.401971</td>\n",
       "      <td>0.402018</td>\n",
       "      <td>0.062627</td>\n",
       "      <td>7.009181</td>\n",
       "      <td>0.371600</td>\n",
       "      <td>0.361592</td>\n",
       "      <td>0.361335</td>\n",
       "      <td>5.264876e-02</td>\n",
       "      <td>6.87663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.269780</td>\n",
       "      <td>0.008474</td>\n",
       "      <td>0.004472</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.096439</td>\n",
       "      <td>0.101040</td>\n",
       "      <td>0.101707</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009644</td>\n",
       "      <td>0.010104</td>\n",
       "      <td>0.010171</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.387779e-17</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.519550</td>\n",
       "      <td>0.038899</td>\n",
       "      <td>0.006486</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.176558</td>\n",
       "      <td>0.268574</td>\n",
       "      <td>0.204714</td>\n",
       "      <td>0.003244</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>0.096694</td>\n",
       "      <td>0.197358</td>\n",
       "      <td>0.122076</td>\n",
       "      <td>0.002774</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>0.173811</td>\n",
       "      <td>0.267528</td>\n",
       "      <td>0.201605</td>\n",
       "      <td>3.019988e-03</td>\n",
       "      <td>6.75000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.882264</td>\n",
       "      <td>0.121928</td>\n",
       "      <td>0.008223</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>0.880564</td>\n",
       "      <td>0.871471</td>\n",
       "      <td>0.868226</td>\n",
       "      <td>0.010055</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>0.881966</td>\n",
       "      <td>0.873867</td>\n",
       "      <td>0.869768</td>\n",
       "      <td>0.010205</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>0.879572</td>\n",
       "      <td>0.869180</td>\n",
       "      <td>0.867289</td>\n",
       "      <td>1.010494e-02</td>\n",
       "      <td>12.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.153042</td>\n",
       "      <td>0.214644</td>\n",
       "      <td>0.009727</td>\n",
       "      <td>0.001998</td>\n",
       "      <td>0.924703</td>\n",
       "      <td>0.932764</td>\n",
       "      <td>0.935041</td>\n",
       "      <td>0.032798</td>\n",
       "      <td>18.250000</td>\n",
       "      <td>0.927331</td>\n",
       "      <td>0.933334</td>\n",
       "      <td>0.935258</td>\n",
       "      <td>0.029558</td>\n",
       "      <td>18.250000</td>\n",
       "      <td>0.923062</td>\n",
       "      <td>0.932389</td>\n",
       "      <td>0.934264</td>\n",
       "      <td>3.223424e-02</td>\n",
       "      <td>18.25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.564564</td>\n",
       "      <td>0.860569</td>\n",
       "      <td>0.014961</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.951039</td>\n",
       "      <td>0.962853</td>\n",
       "      <td>0.954714</td>\n",
       "      <td>0.225238</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.952170</td>\n",
       "      <td>0.963824</td>\n",
       "      <td>0.955877</td>\n",
       "      <td>0.277947</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.950144</td>\n",
       "      <td>0.962549</td>\n",
       "      <td>0.954174</td>\n",
       "      <td>2.246301e-01</td>\n",
       "      <td>22.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "count      24.000000     24.000000        24.000000       24.000000   \n",
       "mean        0.867667      0.166245         0.008398        0.001580   \n",
       "std         0.386487      0.192619         0.002651        0.001287   \n",
       "min         0.269780      0.008474         0.004472        0.000001   \n",
       "25%         0.519550      0.038899         0.006486        0.000508   \n",
       "50%         0.882264      0.121928         0.008223        0.001493   \n",
       "75%         1.153042      0.214644         0.009727        0.001998   \n",
       "max         1.564564      0.860569         0.014961        0.005481   \n",
       "\n",
       "       split0_test_accuracy  split1_test_accuracy  mean_test_accuracy  \\\n",
       "count             24.000000             24.000000           24.000000   \n",
       "mean               0.649790              0.644750            0.647272   \n",
       "std                0.370969              0.360832            0.360611   \n",
       "min                0.096439              0.101040            0.101707   \n",
       "25%                0.176558              0.268574            0.204714   \n",
       "50%                0.880564              0.871471            0.868226   \n",
       "75%                0.924703              0.932764            0.935041   \n",
       "max                0.951039              0.962853            0.954714   \n",
       "\n",
       "       std_test_accuracy  rank_test_accuracy  split0_test_precision_macro  \\\n",
       "count          24.000000           24.000000                    24.000000   \n",
       "mean            0.032585           12.416667                     0.621029   \n",
       "std             0.052631            7.064404                     0.414861   \n",
       "min             0.000667            1.000000                     0.009644   \n",
       "25%             0.003244            6.750000                     0.096694   \n",
       "50%             0.010055           12.500000                     0.881966   \n",
       "75%             0.032798           18.250000                     0.927331   \n",
       "max             0.225238           24.000000                     0.952170   \n",
       "\n",
       "       split1_test_precision_macro  mean_test_precision_macro  \\\n",
       "count                    24.000000                  24.000000   \n",
       "mean                      0.613971                   0.617503   \n",
       "std                       0.401971                   0.402018   \n",
       "min                       0.010104                   0.010171   \n",
       "25%                       0.197358                   0.122076   \n",
       "50%                       0.873867                   0.869768   \n",
       "75%                       0.933334                   0.935258   \n",
       "max                       0.963824                   0.955877   \n",
       "\n",
       "       std_test_precision_macro  rank_test_precision_macro  \\\n",
       "count                 24.000000                  24.000000   \n",
       "mean                   0.035587                  12.458333   \n",
       "std                    0.062627                   7.009181   \n",
       "min                    0.000067                   1.000000   \n",
       "25%                    0.002774                   6.750000   \n",
       "50%                    0.010205                  12.500000   \n",
       "75%                    0.029558                  18.250000   \n",
       "max                    0.277947                  24.000000   \n",
       "\n",
       "       split0_test_recall_macro  split1_test_recall_macro  \\\n",
       "count                 24.000000                 24.000000   \n",
       "mean                   0.648147                  0.643412   \n",
       "std                    0.371600                  0.361592   \n",
       "min                    0.100000                  0.100000   \n",
       "25%                    0.173811                  0.267528   \n",
       "50%                    0.879572                  0.869180   \n",
       "75%                    0.923062                  0.932389   \n",
       "max                    0.950144                  0.962549   \n",
       "\n",
       "       mean_test_recall_macro  std_test_recall_macro  rank_test_recall_macro  \n",
       "count               24.000000           2.400000e+01                24.00000  \n",
       "mean                 0.645781           3.234240e-02                12.37500  \n",
       "std                  0.361335           5.264876e-02                 6.87663  \n",
       "min                  0.100000           1.387779e-17                 1.00000  \n",
       "25%                  0.201605           3.019988e-03                 6.75000  \n",
       "50%                  0.867289           1.010494e-02                12.50000  \n",
       "75%                  0.934264           3.223424e-02                18.25000  \n",
       "max                  0.954174           2.246301e-01                22.00000  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>param_learning_rate_init</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>split0_test_precision_macro</th>\n",
       "      <th>split1_test_precision_macro</th>\n",
       "      <th>mean_test_precision_macro</th>\n",
       "      <th>std_test_precision_macro</th>\n",
       "      <th>rank_test_precision_macro</th>\n",
       "      <th>split0_test_recall_macro</th>\n",
       "      <th>split1_test_recall_macro</th>\n",
       "      <th>mean_test_recall_macro</th>\n",
       "      <th>std_test_recall_macro</th>\n",
       "      <th>rank_test_recall_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.693925</td>\n",
       "      <td>0.043664</td>\n",
       "      <td>0.006490</td>\n",
       "      <td>0.001504</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(20,)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'alpha': 0.05, 'hidden_layer_sizes': (20,), '...</td>\n",
       "      <td>0.939169</td>\n",
       "      <td>0.940565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.938342</td>\n",
       "      <td>0.940506</td>\n",
       "      <td>0.939423</td>\n",
       "      <td>0.001082</td>\n",
       "      <td>6</td>\n",
       "      <td>0.938083</td>\n",
       "      <td>0.939854</td>\n",
       "      <td>0.938968</td>\n",
       "      <td>8.856140e-04</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.990394</td>\n",
       "      <td>0.338588</td>\n",
       "      <td>0.013474</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(20,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.05, 'hidden_layer_sizes': (20,), '...</td>\n",
       "      <td>0.933234</td>\n",
       "      <td>0.928678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.935489</td>\n",
       "      <td>0.930943</td>\n",
       "      <td>0.933218</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>8</td>\n",
       "      <td>0.931943</td>\n",
       "      <td>0.928671</td>\n",
       "      <td>0.930308</td>\n",
       "      <td>1.635885e-03</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.334105</td>\n",
       "      <td>0.215423</td>\n",
       "      <td>0.011977</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(20,)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.05, 'hidden_layer_sizes': (20,), '...</td>\n",
       "      <td>0.200297</td>\n",
       "      <td>0.193165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125415</td>\n",
       "      <td>0.124796</td>\n",
       "      <td>0.125105</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>17</td>\n",
       "      <td>0.198415</td>\n",
       "      <td>0.191452</td>\n",
       "      <td>0.194936</td>\n",
       "      <td>3.481355e-03</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.564564</td>\n",
       "      <td>0.139373</td>\n",
       "      <td>0.010470</td>\n",
       "      <td>0.002492</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(10, 10)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'alpha': 0.05, 'hidden_layer_sizes': (10, 10)...</td>\n",
       "      <td>0.897626</td>\n",
       "      <td>0.906389</td>\n",
       "      <td>...</td>\n",
       "      <td>0.898163</td>\n",
       "      <td>0.906898</td>\n",
       "      <td>0.902527</td>\n",
       "      <td>0.004368</td>\n",
       "      <td>11</td>\n",
       "      <td>0.896200</td>\n",
       "      <td>0.905931</td>\n",
       "      <td>0.901062</td>\n",
       "      <td>4.865222e-03</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.951658</td>\n",
       "      <td>0.133846</td>\n",
       "      <td>0.006489</td>\n",
       "      <td>0.001510</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(10, 10)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.05, 'hidden_layer_sizes': (10, 10)...</td>\n",
       "      <td>0.897626</td>\n",
       "      <td>0.867756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.898353</td>\n",
       "      <td>0.872053</td>\n",
       "      <td>0.885213</td>\n",
       "      <td>0.013150</td>\n",
       "      <td>12</td>\n",
       "      <td>0.896763</td>\n",
       "      <td>0.866642</td>\n",
       "      <td>0.881714</td>\n",
       "      <td>1.506025e-02</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.436332</td>\n",
       "      <td>0.045381</td>\n",
       "      <td>0.008482</td>\n",
       "      <td>0.001488</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(10, 10)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.05, 'hidden_layer_sizes': (10, 10)...</td>\n",
       "      <td>0.096439</td>\n",
       "      <td>0.205052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009644</td>\n",
       "      <td>0.141412</td>\n",
       "      <td>0.075479</td>\n",
       "      <td>0.065884</td>\n",
       "      <td>21</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.199960</td>\n",
       "      <td>0.149943</td>\n",
       "      <td>4.997987e-02</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.363356</td>\n",
       "      <td>0.038894</td>\n",
       "      <td>0.004985</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(10, 5, 5)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'alpha': 0.05, 'hidden_layer_sizes': (10, 5, ...</td>\n",
       "      <td>0.816024</td>\n",
       "      <td>0.875186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.824809</td>\n",
       "      <td>0.875681</td>\n",
       "      <td>0.850226</td>\n",
       "      <td>0.025436</td>\n",
       "      <td>14</td>\n",
       "      <td>0.814228</td>\n",
       "      <td>0.871717</td>\n",
       "      <td>0.842951</td>\n",
       "      <td>2.874492e-02</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.053685</td>\n",
       "      <td>0.008474</td>\n",
       "      <td>0.005990</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(10, 5, 5)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.05, 'hidden_layer_sizes': (10, 5, ...</td>\n",
       "      <td>0.829377</td>\n",
       "      <td>0.378900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.832679</td>\n",
       "      <td>0.276785</td>\n",
       "      <td>0.554938</td>\n",
       "      <td>0.277947</td>\n",
       "      <td>16</td>\n",
       "      <td>0.828132</td>\n",
       "      <td>0.378872</td>\n",
       "      <td>0.603668</td>\n",
       "      <td>2.246301e-01</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.512620</td>\n",
       "      <td>0.010958</td>\n",
       "      <td>0.008480</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(10, 5, 5)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.05, 'hidden_layer_sizes': (10, 5, ...</td>\n",
       "      <td>0.103858</td>\n",
       "      <td>0.101040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010386</td>\n",
       "      <td>0.010104</td>\n",
       "      <td>0.010245</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>22</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.387779e-17</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.145439</td>\n",
       "      <td>0.011475</td>\n",
       "      <td>0.006478</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(20, 20)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'alpha': 0.05, 'hidden_layer_sizes': (20, 20)...</td>\n",
       "      <td>0.930267</td>\n",
       "      <td>0.950966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931419</td>\n",
       "      <td>0.950498</td>\n",
       "      <td>0.940951</td>\n",
       "      <td>0.009539</td>\n",
       "      <td>4</td>\n",
       "      <td>0.928867</td>\n",
       "      <td>0.950288</td>\n",
       "      <td>0.939569</td>\n",
       "      <td>1.071028e-02</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.493168</td>\n",
       "      <td>0.012469</td>\n",
       "      <td>0.008497</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(20, 20)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.05, 'hidden_layer_sizes': (20, 20)...</td>\n",
       "      <td>0.946588</td>\n",
       "      <td>0.961367</td>\n",
       "      <td>...</td>\n",
       "      <td>0.946865</td>\n",
       "      <td>0.961547</td>\n",
       "      <td>0.954201</td>\n",
       "      <td>0.007341</td>\n",
       "      <td>2</td>\n",
       "      <td>0.945872</td>\n",
       "      <td>0.960922</td>\n",
       "      <td>0.953391</td>\n",
       "      <td>7.524991e-03</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.962295</td>\n",
       "      <td>0.860569</td>\n",
       "      <td>0.014961</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(20, 20)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.05, 'hidden_layer_sizes': (20, 20)...</td>\n",
       "      <td>0.100890</td>\n",
       "      <td>0.104012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010089</td>\n",
       "      <td>0.010401</td>\n",
       "      <td>0.010245</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>22</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.387779e-17</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.298816</td>\n",
       "      <td>0.110010</td>\n",
       "      <td>0.004472</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(20,)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'alpha': 0.1, 'hidden_layer_sizes': (20,), 'l...</td>\n",
       "      <td>0.922849</td>\n",
       "      <td>0.953938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.925968</td>\n",
       "      <td>0.953149</td>\n",
       "      <td>0.939548</td>\n",
       "      <td>0.013590</td>\n",
       "      <td>5</td>\n",
       "      <td>0.921127</td>\n",
       "      <td>0.953182</td>\n",
       "      <td>0.937143</td>\n",
       "      <td>1.602735e-02</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.704386</td>\n",
       "      <td>0.154856</td>\n",
       "      <td>0.008478</td>\n",
       "      <td>0.003491</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(20,)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.1, 'hidden_layer_sizes': (20,), 'l...</td>\n",
       "      <td>0.946588</td>\n",
       "      <td>0.962853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947941</td>\n",
       "      <td>0.963824</td>\n",
       "      <td>0.955877</td>\n",
       "      <td>0.007942</td>\n",
       "      <td>1</td>\n",
       "      <td>0.945812</td>\n",
       "      <td>0.962549</td>\n",
       "      <td>0.954174</td>\n",
       "      <td>8.368477e-03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.427856</td>\n",
       "      <td>0.075798</td>\n",
       "      <td>0.007502</td>\n",
       "      <td>0.001482</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(20,)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.1, 'hidden_layer_sizes': (20,), 'l...</td>\n",
       "      <td>0.323442</td>\n",
       "      <td>0.104012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228069</td>\n",
       "      <td>0.010401</td>\n",
       "      <td>0.119316</td>\n",
       "      <td>0.108834</td>\n",
       "      <td>19</td>\n",
       "      <td>0.316918</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.208540</td>\n",
       "      <td>1.084590e-01</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.551547</td>\n",
       "      <td>0.306872</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.003493</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(10, 10)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'alpha': 0.1, 'hidden_layer_sizes': (10, 10),...</td>\n",
       "      <td>0.910979</td>\n",
       "      <td>0.909361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.915549</td>\n",
       "      <td>0.909666</td>\n",
       "      <td>0.912609</td>\n",
       "      <td>0.002942</td>\n",
       "      <td>9</td>\n",
       "      <td>0.909601</td>\n",
       "      <td>0.908919</td>\n",
       "      <td>0.909260</td>\n",
       "      <td>3.412726e-04</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.812870</td>\n",
       "      <td>0.214384</td>\n",
       "      <td>0.005985</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(10, 10)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.1, 'hidden_layer_sizes': (10, 10),...</td>\n",
       "      <td>0.902077</td>\n",
       "      <td>0.919762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.901806</td>\n",
       "      <td>0.921138</td>\n",
       "      <td>0.911465</td>\n",
       "      <td>0.009666</td>\n",
       "      <td>10</td>\n",
       "      <td>0.901367</td>\n",
       "      <td>0.919010</td>\n",
       "      <td>0.910182</td>\n",
       "      <td>8.821449e-03</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.521861</td>\n",
       "      <td>0.452049</td>\n",
       "      <td>0.005484</td>\n",
       "      <td>0.001496</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(10, 10)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.1, 'hidden_layer_sizes': (10, 10),...</td>\n",
       "      <td>0.102374</td>\n",
       "      <td>0.101040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010237</td>\n",
       "      <td>0.010104</td>\n",
       "      <td>0.010171</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>24</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.387779e-17</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.175851</td>\n",
       "      <td>0.038901</td>\n",
       "      <td>0.009480</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(10, 5, 5)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'alpha': 0.1, 'hidden_layer_sizes': (10, 5, 5...</td>\n",
       "      <td>0.863501</td>\n",
       "      <td>0.843982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.865059</td>\n",
       "      <td>0.843572</td>\n",
       "      <td>0.854323</td>\n",
       "      <td>0.010743</td>\n",
       "      <td>13</td>\n",
       "      <td>0.862944</td>\n",
       "      <td>0.842769</td>\n",
       "      <td>0.852864</td>\n",
       "      <td>1.008786e-02</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.107032</td>\n",
       "      <td>0.335100</td>\n",
       "      <td>0.010474</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(10, 5, 5)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.1, 'hidden_layer_sizes': (10, 5, 5...</td>\n",
       "      <td>0.862018</td>\n",
       "      <td>0.777117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.865769</td>\n",
       "      <td>0.781920</td>\n",
       "      <td>0.823876</td>\n",
       "      <td>0.041925</td>\n",
       "      <td>15</td>\n",
       "      <td>0.860642</td>\n",
       "      <td>0.775238</td>\n",
       "      <td>0.817971</td>\n",
       "      <td>4.270220e-02</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.565755</td>\n",
       "      <td>0.179252</td>\n",
       "      <td>0.007492</td>\n",
       "      <td>0.001507</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(10, 5, 5)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.1, 'hidden_layer_sizes': (10, 5, 5...</td>\n",
       "      <td>0.103858</td>\n",
       "      <td>0.310550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010386</td>\n",
       "      <td>0.216006</td>\n",
       "      <td>0.113120</td>\n",
       "      <td>0.102810</td>\n",
       "      <td>20</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.307797</td>\n",
       "      <td>0.203821</td>\n",
       "      <td>1.038982e-01</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.247914</td>\n",
       "      <td>0.015211</td>\n",
       "      <td>0.007497</td>\n",
       "      <td>0.001492</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(20, 20)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'alpha': 0.1, 'hidden_layer_sizes': (20, 20),...</td>\n",
       "      <td>0.909496</td>\n",
       "      <td>0.958395</td>\n",
       "      <td>...</td>\n",
       "      <td>0.909548</td>\n",
       "      <td>0.958227</td>\n",
       "      <td>0.933869</td>\n",
       "      <td>0.024340</td>\n",
       "      <td>7</td>\n",
       "      <td>0.908477</td>\n",
       "      <td>0.958168</td>\n",
       "      <td>0.933304</td>\n",
       "      <td>2.484569e-02</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.638788</td>\n",
       "      <td>0.059337</td>\n",
       "      <td>0.007972</td>\n",
       "      <td>0.000989</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(20, 20)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.1, 'hidden_layer_sizes': (20, 20),...</td>\n",
       "      <td>0.951039</td>\n",
       "      <td>0.930163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.952170</td>\n",
       "      <td>0.930052</td>\n",
       "      <td>0.941119</td>\n",
       "      <td>0.011059</td>\n",
       "      <td>3</td>\n",
       "      <td>0.950144</td>\n",
       "      <td>0.929900</td>\n",
       "      <td>0.940030</td>\n",
       "      <td>1.012201e-02</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.269780</td>\n",
       "      <td>0.188993</td>\n",
       "      <td>0.011468</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(20, 20)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.1, 'hidden_layer_sizes': (20, 20),...</td>\n",
       "      <td>0.105341</td>\n",
       "      <td>0.289747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010534</td>\n",
       "      <td>0.235625</td>\n",
       "      <td>0.122996</td>\n",
       "      <td>0.112545</td>\n",
       "      <td>18</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.290051</td>\n",
       "      <td>0.194955</td>\n",
       "      <td>9.502542e-02</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24 rows  23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0        0.693925      0.043664         0.006490        0.001504        0.05   \n",
       "1        0.990394      0.338588         0.013474        0.000510        0.05   \n",
       "2        0.334105      0.215423         0.011977        0.000002        0.05   \n",
       "3        1.564564      0.139373         0.010470        0.002492        0.05   \n",
       "4        0.951658      0.133846         0.006489        0.001510        0.05   \n",
       "5        0.436332      0.045381         0.008482        0.001488        0.05   \n",
       "6        1.363356      0.038894         0.004985        0.000001        0.05   \n",
       "7        1.053685      0.008474         0.005990        0.002002        0.05   \n",
       "8        0.512620      0.010958         0.008480        0.001493        0.05   \n",
       "9        1.145439      0.011475         0.006478        0.000496        0.05   \n",
       "10       0.493168      0.012469         0.008497        0.000481        0.05   \n",
       "11       0.962295      0.860569         0.014961        0.002991        0.05   \n",
       "12       1.298816      0.110010         0.004472        0.000513         0.1   \n",
       "13       0.704386      0.154856         0.008478        0.003491         0.1   \n",
       "14       0.427856      0.075798         0.007502        0.001482         0.1   \n",
       "15       1.551547      0.306872         0.008475        0.003493         0.1   \n",
       "16       0.812870      0.214384         0.005985        0.001997         0.1   \n",
       "17       0.521861      0.452049         0.005484        0.001496         0.1   \n",
       "18       1.175851      0.038901         0.009480        0.000494         0.1   \n",
       "19       1.107032      0.335100         0.010474        0.005481         0.1   \n",
       "20       0.565755      0.179252         0.007492        0.001507         0.1   \n",
       "21       1.247914      0.015211         0.007497        0.001492         0.1   \n",
       "22       0.638788      0.059337         0.007972        0.000989         0.1   \n",
       "23       0.269780      0.188993         0.011468        0.000501         0.1   \n",
       "\n",
       "   param_hidden_layer_sizes param_learning_rate_init  \\\n",
       "0                     (20,)                    0.001   \n",
       "1                     (20,)                     0.01   \n",
       "2                     (20,)                      0.1   \n",
       "3                  (10, 10)                    0.001   \n",
       "4                  (10, 10)                     0.01   \n",
       "5                  (10, 10)                      0.1   \n",
       "6                (10, 5, 5)                    0.001   \n",
       "7                (10, 5, 5)                     0.01   \n",
       "8                (10, 5, 5)                      0.1   \n",
       "9                  (20, 20)                    0.001   \n",
       "10                 (20, 20)                     0.01   \n",
       "11                 (20, 20)                      0.1   \n",
       "12                    (20,)                    0.001   \n",
       "13                    (20,)                     0.01   \n",
       "14                    (20,)                      0.1   \n",
       "15                 (10, 10)                    0.001   \n",
       "16                 (10, 10)                     0.01   \n",
       "17                 (10, 10)                      0.1   \n",
       "18               (10, 5, 5)                    0.001   \n",
       "19               (10, 5, 5)                     0.01   \n",
       "20               (10, 5, 5)                      0.1   \n",
       "21                 (20, 20)                    0.001   \n",
       "22                 (20, 20)                     0.01   \n",
       "23                 (20, 20)                      0.1   \n",
       "\n",
       "                                               params  split0_test_accuracy  \\\n",
       "0   {'alpha': 0.05, 'hidden_layer_sizes': (20,), '...              0.939169   \n",
       "1   {'alpha': 0.05, 'hidden_layer_sizes': (20,), '...              0.933234   \n",
       "2   {'alpha': 0.05, 'hidden_layer_sizes': (20,), '...              0.200297   \n",
       "3   {'alpha': 0.05, 'hidden_layer_sizes': (10, 10)...              0.897626   \n",
       "4   {'alpha': 0.05, 'hidden_layer_sizes': (10, 10)...              0.897626   \n",
       "5   {'alpha': 0.05, 'hidden_layer_sizes': (10, 10)...              0.096439   \n",
       "6   {'alpha': 0.05, 'hidden_layer_sizes': (10, 5, ...              0.816024   \n",
       "7   {'alpha': 0.05, 'hidden_layer_sizes': (10, 5, ...              0.829377   \n",
       "8   {'alpha': 0.05, 'hidden_layer_sizes': (10, 5, ...              0.103858   \n",
       "9   {'alpha': 0.05, 'hidden_layer_sizes': (20, 20)...              0.930267   \n",
       "10  {'alpha': 0.05, 'hidden_layer_sizes': (20, 20)...              0.946588   \n",
       "11  {'alpha': 0.05, 'hidden_layer_sizes': (20, 20)...              0.100890   \n",
       "12  {'alpha': 0.1, 'hidden_layer_sizes': (20,), 'l...              0.922849   \n",
       "13  {'alpha': 0.1, 'hidden_layer_sizes': (20,), 'l...              0.946588   \n",
       "14  {'alpha': 0.1, 'hidden_layer_sizes': (20,), 'l...              0.323442   \n",
       "15  {'alpha': 0.1, 'hidden_layer_sizes': (10, 10),...              0.910979   \n",
       "16  {'alpha': 0.1, 'hidden_layer_sizes': (10, 10),...              0.902077   \n",
       "17  {'alpha': 0.1, 'hidden_layer_sizes': (10, 10),...              0.102374   \n",
       "18  {'alpha': 0.1, 'hidden_layer_sizes': (10, 5, 5...              0.863501   \n",
       "19  {'alpha': 0.1, 'hidden_layer_sizes': (10, 5, 5...              0.862018   \n",
       "20  {'alpha': 0.1, 'hidden_layer_sizes': (10, 5, 5...              0.103858   \n",
       "21  {'alpha': 0.1, 'hidden_layer_sizes': (20, 20),...              0.909496   \n",
       "22  {'alpha': 0.1, 'hidden_layer_sizes': (20, 20),...              0.951039   \n",
       "23  {'alpha': 0.1, 'hidden_layer_sizes': (20, 20),...              0.105341   \n",
       "\n",
       "    split1_test_accuracy  ...  split0_test_precision_macro  \\\n",
       "0               0.940565  ...                     0.938342   \n",
       "1               0.928678  ...                     0.935489   \n",
       "2               0.193165  ...                     0.125415   \n",
       "3               0.906389  ...                     0.898163   \n",
       "4               0.867756  ...                     0.898353   \n",
       "5               0.205052  ...                     0.009644   \n",
       "6               0.875186  ...                     0.824809   \n",
       "7               0.378900  ...                     0.832679   \n",
       "8               0.101040  ...                     0.010386   \n",
       "9               0.950966  ...                     0.931419   \n",
       "10              0.961367  ...                     0.946865   \n",
       "11              0.104012  ...                     0.010089   \n",
       "12              0.953938  ...                     0.925968   \n",
       "13              0.962853  ...                     0.947941   \n",
       "14              0.104012  ...                     0.228069   \n",
       "15              0.909361  ...                     0.915549   \n",
       "16              0.919762  ...                     0.901806   \n",
       "17              0.101040  ...                     0.010237   \n",
       "18              0.843982  ...                     0.865059   \n",
       "19              0.777117  ...                     0.865769   \n",
       "20              0.310550  ...                     0.010386   \n",
       "21              0.958395  ...                     0.909548   \n",
       "22              0.930163  ...                     0.952170   \n",
       "23              0.289747  ...                     0.010534   \n",
       "\n",
       "    split1_test_precision_macro  mean_test_precision_macro  \\\n",
       "0                      0.940506                   0.939423   \n",
       "1                      0.930943                   0.933218   \n",
       "2                      0.124796                   0.125105   \n",
       "3                      0.906898                   0.902527   \n",
       "4                      0.872053                   0.885213   \n",
       "5                      0.141412                   0.075479   \n",
       "6                      0.875681                   0.850226   \n",
       "7                      0.276785                   0.554938   \n",
       "8                      0.010104                   0.010245   \n",
       "9                      0.950498                   0.940951   \n",
       "10                     0.961547                   0.954201   \n",
       "11                     0.010401                   0.010245   \n",
       "12                     0.953149                   0.939548   \n",
       "13                     0.963824                   0.955877   \n",
       "14                     0.010401                   0.119316   \n",
       "15                     0.909666                   0.912609   \n",
       "16                     0.921138                   0.911465   \n",
       "17                     0.010104                   0.010171   \n",
       "18                     0.843572                   0.854323   \n",
       "19                     0.781920                   0.823876   \n",
       "20                     0.216006                   0.113120   \n",
       "21                     0.958227                   0.933869   \n",
       "22                     0.930052                   0.941119   \n",
       "23                     0.235625                   0.122996   \n",
       "\n",
       "    std_test_precision_macro  rank_test_precision_macro  \\\n",
       "0                   0.001082                          6   \n",
       "1                   0.002273                          8   \n",
       "2                   0.000309                         17   \n",
       "3                   0.004368                         11   \n",
       "4                   0.013150                         12   \n",
       "5                   0.065884                         21   \n",
       "6                   0.025436                         14   \n",
       "7                   0.277947                         16   \n",
       "8                   0.000141                         22   \n",
       "9                   0.009539                          4   \n",
       "10                  0.007341                          2   \n",
       "11                  0.000156                         22   \n",
       "12                  0.013590                          5   \n",
       "13                  0.007942                          1   \n",
       "14                  0.108834                         19   \n",
       "15                  0.002942                          9   \n",
       "16                  0.009666                         10   \n",
       "17                  0.000067                         24   \n",
       "18                  0.010743                         13   \n",
       "19                  0.041925                         15   \n",
       "20                  0.102810                         20   \n",
       "21                  0.024340                          7   \n",
       "22                  0.011059                          3   \n",
       "23                  0.112545                         18   \n",
       "\n",
       "    split0_test_recall_macro  split1_test_recall_macro  \\\n",
       "0                   0.938083                  0.939854   \n",
       "1                   0.931943                  0.928671   \n",
       "2                   0.198415                  0.191452   \n",
       "3                   0.896200                  0.905931   \n",
       "4                   0.896763                  0.866642   \n",
       "5                   0.100000                  0.199960   \n",
       "6                   0.814228                  0.871717   \n",
       "7                   0.828132                  0.378872   \n",
       "8                   0.100000                  0.100000   \n",
       "9                   0.928867                  0.950288   \n",
       "10                  0.945872                  0.960922   \n",
       "11                  0.100000                  0.100000   \n",
       "12                  0.921127                  0.953182   \n",
       "13                  0.945812                  0.962549   \n",
       "14                  0.316918                  0.100000   \n",
       "15                  0.909601                  0.908919   \n",
       "16                  0.901367                  0.919010   \n",
       "17                  0.100000                  0.100000   \n",
       "18                  0.862944                  0.842769   \n",
       "19                  0.860642                  0.775238   \n",
       "20                  0.100000                  0.307797   \n",
       "21                  0.908477                  0.958168   \n",
       "22                  0.950144                  0.929900   \n",
       "23                  0.100000                  0.290051   \n",
       "\n",
       "    mean_test_recall_macro  std_test_recall_macro  rank_test_recall_macro  \n",
       "0                 0.938968           8.856140e-04                       5  \n",
       "1                 0.930308           1.635885e-03                       8  \n",
       "2                 0.194936           3.481355e-03                      20  \n",
       "3                 0.901062           4.865222e-03                      11  \n",
       "4                 0.881714           1.506025e-02                      12  \n",
       "5                 0.149943           4.997987e-02                      21  \n",
       "6                 0.842951           2.874492e-02                      14  \n",
       "7                 0.603668           2.246301e-01                      16  \n",
       "8                 0.100000           1.387779e-17                      22  \n",
       "9                 0.939569           1.071028e-02                       4  \n",
       "10                0.953391           7.524991e-03                       2  \n",
       "11                0.100000           1.387779e-17                      22  \n",
       "12                0.937143           1.602735e-02                       6  \n",
       "13                0.954174           8.368477e-03                       1  \n",
       "14                0.208540           1.084590e-01                      17  \n",
       "15                0.909260           3.412726e-04                      10  \n",
       "16                0.910182           8.821449e-03                       9  \n",
       "17                0.100000           1.387779e-17                      22  \n",
       "18                0.852864           1.008786e-02                      13  \n",
       "19                0.817971           4.270220e-02                      15  \n",
       "20                0.203821           1.038982e-01                      18  \n",
       "21                0.933304           2.484569e-02                       7  \n",
       "22                0.940030           1.012201e-02                       3  \n",
       "23                0.194955           9.502542e-02                      19  \n",
       "\n",
       "[24 rows x 23 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e51a5ca8c8>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(data=df, x='param_alpha', y='mean_test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = pd.pivot_table(data=df,\n",
    "            index='param_learning_rate_init', \n",
    "            columns='param_hidden_layer_sizes',\n",
    "            values = 'mean_test_accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>(10, 5, 5)</th>\n",
       "      <th>(10, 10)</th>\n",
       "      <th>(20,)</th>\n",
       "      <th>(20, 20)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_learning_rate_init</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0.001</td>\n",
       "      <td>0.849666</td>\n",
       "      <td>0.906088</td>\n",
       "      <td>0.939124</td>\n",
       "      <td>0.937268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.010</td>\n",
       "      <td>0.711952</td>\n",
       "      <td>0.896808</td>\n",
       "      <td>0.942836</td>\n",
       "      <td>0.947290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.100</td>\n",
       "      <td>0.154788</td>\n",
       "      <td>0.126206</td>\n",
       "      <td>0.205271</td>\n",
       "      <td>0.149963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "param_hidden_layer_sizes  (10, 5, 5)  (10, 10)     (20,)  (20, 20)\n",
       "param_learning_rate_init                                          \n",
       "0.001                       0.849666  0.906088  0.939124  0.937268\n",
       "0.010                       0.711952  0.896808  0.942836  0.947290\n",
       "0.100                       0.154788  0.126206  0.205271  0.149963"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e51a8bcf88>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(data=pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = pd.pivot_table(df, index='param_learning_rate_init', columns='param_hidden_layer_sizes', values='mean_test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>(10, 5, 5)</th>\n",
       "      <th>(10, 10)</th>\n",
       "      <th>(20,)</th>\n",
       "      <th>(20, 20)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_learning_rate_init</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0.001</td>\n",
       "      <td>0.849666</td>\n",
       "      <td>0.906088</td>\n",
       "      <td>0.939124</td>\n",
       "      <td>0.937268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.010</td>\n",
       "      <td>0.711952</td>\n",
       "      <td>0.896808</td>\n",
       "      <td>0.942836</td>\n",
       "      <td>0.947290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.100</td>\n",
       "      <td>0.154788</td>\n",
       "      <td>0.126206</td>\n",
       "      <td>0.205271</td>\n",
       "      <td>0.149963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "param_hidden_layer_sizes  (10, 5, 5)  (10, 10)     (20,)  (20, 20)\n",
       "param_learning_rate_init                                          \n",
       "0.001                       0.849666  0.906088  0.939124  0.937268\n",
       "0.010                       0.711952  0.896808  0.942836  0.947290\n",
       "0.100                       0.154788  0.126206  0.205271  0.149963"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e51a35ab48>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(data=pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
